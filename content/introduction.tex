\section{Introduction}

In recent years, the field of machine learning has evolved from an emerging science into a widely applied technology, finding applications across various domains such as business, industry, and scientific research. However, as machine learning techniques have gained prominence, a critical challenge has surfaced known as the class imbalance problem. This problem, characterized by a significant disparity in the number of samples between different classes within a dataset, has profound implications for classification performance and decision-making in real-world applications.
It has become increasingly apparent that imbalanced datasets can lead to suboptimal classification results, prompting researchers to explore solutions to mitigate its impact. The class imbalance problem is widespread, affecting a substantial portion of the data mining community. It is essential to understand that class imbalances can manifest in various application domains, including fraud detection, risk management, text classification, and biomedical context. This term refers to datasets characterized by a substantial disparity in the frequency of observed class labels, where one class significantly outnumbers the others~\cite{OBrien2019,Tarawneh2020}. In some cases, these imbalances are inherent to the problem, while in others, they arise due to limitations in data collection processes or the need for human intervention in selecting examples for training.
 
Over the years, extensive research has been dedicated to exploring diverse approaches for handling imbalanced data classification. These methods can broadly be categorized into three distinct groups: data-level methods, algorithm-level methods, and hybrid methods. 


\textbf{Data-Level Methods} 

It has become increasingly apparent that imbalanced datasets can lead to suboptimal classification results, prompting researchers to explore solutions to mitigate its impact. 
The class imbalance problem is widespread, affecting a substantial portion of the data mining community.
It is essential to understand that class imbalances can manifest in various application domains, including fraud detection, risk management, text classification, and medical diagnosis. In some cases, these imbalances are inherent to the problem, while in others, they arise due to limitations in data collection processes or the need for human intervention in selecting examples for training.

Data-level methods play a crucial role in mitigating class imbalance issues by manipulating the training data to achieve a more balanced class distribution. This is primarily accomplished through resampling techniques during the data pre-processing stage. Resampling involves redistributing the training data across different classes in the data space, with the aim of restructuring the dataset to address class imbalances effectively. Research has shown that resampling can notably enhance the model's performance by adjusting the analog distribution of samples. 
These methods can be further categorized into under-sampling, over-sampling, and hybrid approaches. Under-sampling involves reducing the number of samples in the majority class, while over-sampling focuses on augmenting the samples in the minority class. Hybrid methods combine elements of both under-sampling and over-sampling techniques to achieve a balanced dataset. It's important to note that the selection of target samples for pre-processing is a critical consideration. Random approaches, while common, can lead to the inadvertent removal of crucial samples or the introduction of synthetic data lacking meaningful representation. Consequently, more advanced methods have been proposed to preserve the underlying group structures and generate new data in accordance with the inherent distributions.
Moreover, data-level methods extend beyond mere balancing efforts. They also encompass procedures for cleaning overlapping objects and removing noisy examples, which can have detrimental effects on the performance of learning algorithms. These comprehensive approaches collectively form a critical component in addressing the challenges posed by imbalanced datasets~\cite{Krawczyk2016,Fotouhi2019,Khushi2021}. 

Under-sampling methods encompass a range of techniques aimed at addressing class imbalance by strategically reducing the number of samples, particularly from the majority class. These methodologies are pivotal in rectifying skewed class distributions, thus enhancing the learning process. A variety of under-sampling techniques have been proposed, each with its distinct approach: 

\textbf{Random Under-Sampling (RUS):} This pioneering method involves the random removal of samples from the majority class, thus equalizing class frequencies. 

\textbf{All k-Nearest Neighbors (All k-NN):} This approach leverages the k-NN algorithm to classify test samples based on the classifications of their k nearest neighbors. Instances that are predominantly misclassified by their neighbors are subsequently discarded. 

\textbf{Cluster Centroids:} This method employs k-means clustering to identify cluster centroids, which are then used to replace the majority class samples, effectively reducing the sample count. Edited Nearest Neighbors (ENN): ENN utilizes the k-NN algorithm to assess each instance. Misclassified instances are removed, resulting in an edited dataset. 

\textbf{Instance Hardness Threshold (IHT): }This method initially trains a classifier to identify instances with a high likelihood of misclassification. These identified instances are then removed from the dataset. 

\textbf{Near Miss:} This technique focuses on selecting majority samples that are in close proximity to minority samples, as determined by their distances. 

\textbf{Neighbourhood Cleaning Rule (NCR):} By considering the three nearest neighbors of each instance, NCR identifies misclassified samples from both majority and minority classes, subsequently removing them from the dataset. 

\textbf{One-Sided Selection (OSS):} OSS involves the selection of minority class samples and misclassified majority samples using the 1-NN algorithm. Majority class samples within Tomek Links are then removed. 

\textbf{Repeated ENN:} This iterative method continues to apply ENN until further elimination no longer affects the edited training set. 

\textbf{Tomek Links (TL):} Instances a and b are deemed Tomek Links if they belong to different classes and are each other's nearest neighbor. These instances are considered boundary or noisy instances, and the majority class sample is removed. 

\textbf{Condensed Nearest Neighbour (CNN):} CNN iteratively applies the nearest neighbor algorithm, combining majority and minority class samples into a set. Misclassified samples are added to this set in each iteration. 

These under-sampling techniques serve as essential tools in rectifying class imbalances, thereby facilitating more accurate and reliable machine learning models. Each method addresses specific aspects of the imbalanced data challenge, ensuring a nuanced and comprehensive approach to dataset pre-processing \cite{Fotouhi2019,Khushi2021}.

Over-sampling methods play a pivotal role in mitigating class imbalance issues by artificially increasing the representation of the minority class. Unlike under-sampling algorithms that deal with samples in the majority class, over-sampling strategies focus exclusively on augmenting the minority class samples. This approach aims to improve classification performance by achieving a more balanced class distribution. However, it is imperative to recognize that over-sampling can introduce challenges. The process of generating new samples, often through duplication or synthesis, may lead to overfitting, as it entails an expansion of a subset of the minority class. Additionally, as the number of samples increases, so does the computational demand, resulting in longer training times. The prevalence of over-sampling methods in addressing class imbalance underscores their significance in machine learning. Nevertheless, it is essential to approach these techniques judiciously, as indiscriminate application may inadvertently lead to overfitting, necessitating a nuanced consideration of their suitability for specific datasets~\cite{Khushi2021,Tarawneh2022,Xu2020,Liu2022}.

\textbf{Synthetic Minority Over-Sampling Technique (SMOTE):} SMOTE is a pioneering algorithm devised~\cite{Chawla2002} to address class imbalance. By interpolating synthetic instances based on the k Nearest Neighbors of each minority sample, SMOTE effectively augments the representation of the minority class. However, it's important to note that SMOTE's indiscriminate generation of synthetic instances can potentially alter class boundaries. Despite this, SMOTE remains a widely used method for mitigating the impact of class imbalance, offering a balanced representation through the interpolation of synthetic samples between nearest neighbors.

\textbf{ADASYN (Adaptive Synthetic):} This approach introduces a weighted distribution for different samples within the minority class, taking into account their varying levels of learning complexity. It strategically generates additional synthetic data for samples that pose greater learning challenges.

\textbf{ADOMS (Adaptive One-Dimensional Minority Over-sampling):} Operating along the first principal component axis of locally distributed data, ADOMS produces synthetic samples with precision.

\textbf{AHC (Artificial Hierarchical Cascade):} This technique selectively targets a subset class, subsequently re-integrating the generated synthetic samples into the primary dataset.

\textbf{Borderline-SMOTE:} Aiming for improved predictive accuracy, this method capitalizes on the fact that samples proximal to classification boundaries are more crucial for accurate classification. By leveraging SMOTE, it strategically oversamples the minority class, particularly those residing near the classification borderline.

\textbf{ROS (Random Over-Sampling):} ROS takes a random approach, generating fresh samples for the minority class until a balanced distribution is attained, ensuring an equal number of samples in both classes.

\textbf{Safe-Level-SMOTE:} Prior to synthetic sample generation, this technique assesses the secure level of minority class samples based on SMOTE principles. Synthetic samples are judiciously placed at the identified secure levels, effectively managing the synthetic sample generation process~\cite{Tarawneh2020,Fotouhi2019,Khushi2021}⁠. 


\textbf{Algorithm-level Methods} 
Algorithm-level methods entail two main approaches: firstly, the modification of standard machine learning classifiers to incorporate a weight or cost variable, and secondly, the development of classifiers that remain unaffected by skewed class distributions. Researchers have extensively explored and published research findings addressing the class-imbalanced problem within the realm of algorithm-level techniques. This category encompasses techniques like cost-sensitive learning and ensemble machine learning models, which are expressly designed and optimized to process data characterized by class imbalance, offering a sophisticated framework for handling these challenging scenarios.


\textbf{Hybrid Methods} 
Hybrid resampling methods represent a strategic fusion of both under-sampling and over-sampling techniques, each of which carries its own set of advantages and drawbacks. While under-sampling may inadvertently discard valuable information, over-sampling can potentially lead to overfitting. The concept underlying hybrid resampling is to concurrently augment the number of minority samples and diminish the number of majority samples, effectively mitigating sample imbalance. Researchers have made significant strides in devising hybrid techniques to address these inherent challenges. 

\textbf{SMOTE-ENN:} SMOTE-ENN is a potent hybrid technique that marries the strengths of SMOTE and Edited Nearest Neighbors (ENN) to refine the data preprocessing stage. ENN plays a crucial role in this method, serving as a robust filter to identify and eliminate noisy data points. It contributes to the elimination of misclassified samples by considering their three nearest neighbors. This combination of SMOTE and ENN not only augments the dataset through oversampling but also ensures that noisy elements are effectively culled, resulting in a more balanced and reliable training set.

\textbf{SMOTE-TL:} SMOTE-TL represents another impactful hybrid technique, leveraging the power of SMOTE alongside Tomek links to fine-tune the dataset. Tomek links are pairs of samples that, despite being nearest neighbors, belong to different classes. By applying SMOTE, this technique intelligently identifies and eliminates samples that form Tomek links. This process not only leads to an augmented dataset but also ensures well-defined class clusters. The outcome is a balanced dataset with enhanced class separation, setting the stage for the creation of models with superior generalization capabilities~\cite{Fotouhi2019,Xu2020,Khushi2021}.

Both data-level and algorithmic-level solutions have been proposed to address class imbalance.
These include resampling techniques such as oversampling and undersampling, adjustments to class-specific costs, threshold tuning, and recognition-based learning approaches. Researchers have dedicated considerable effort to developing and refining these methods, aiming to improve the performance and fairness of machine learning models in the face of imbalanced data.

In this report, we illustrate a comparative analysis aiming to highlight the influence of data balancing and other factors in the process of classifying imbalanced datasets. In addition to assessing the performance of established data-level balancing algorithms, our objective includes the exploration of diverse classification scenarios wherein various factors may exert an influence on classification efficacy.

The report is organized into distinct sections, including Methods, Results, and Discussion. Within the Methods section, we comprehensively elucidate our approach, which comprises a four-step pipeline encompassing data generation, balancing, classification, and output analysis. It’s noteworthy to emphasize that each step of this methodology is supported by extensive literature research, ensuring a robust foundation for our approach.

In the Results section, we provide the most significant findings derived from the systematic variation of parameters within our defined pipeline. Through rigorous experimentation, we explore the impact of parameter adjustments on the classification outcomes. To facilitate a comprehensive understanding of our findings, we employ data visualization techniques and provide insightful plots that vividly represent the observed results.

In the final section, the Discussion, we delve into a thorough analysis of the results and draw meaningful conclusions from our study. We closely examine what our findings mean in practical terms and how they can be applied in real-world situations. Additionally, we consider areas where our study could be improved or enhanced for future research. By acknowledging both the strengths and limitations of our work, we lay the groundwork for future studies to build upon our findings and advance the field of classifying imbalanced datasets. 



 
